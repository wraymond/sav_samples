---
title: "Bayes_approaches"
author: "Wendel Raymond"
date: "`r Sys.Date()`"
output: html_document
editor_options: 
  chunk_output_type: console
---
```{r}
library(tidyverse)
library(HDInterval)
library(BayesFactor)
library(rjags)
library(kableExtra)
library(ggmcmc)
library(polspline)
library(propagate)
library(multcomp)
library(pwr)
```


## Bayesian appraoches to SAV calculations
Following Hobbs and Hooten texts and code. Bayes Theorem Lab from Bayesian Modeling for Ecologists

You are interested in estimating the posterior distribution for the mean number of individuals of an invasive plant species per m2 in a disturbed grassland (or we can think eelgrass shoots). We will call that mean θ (mean shoot density). You have prior information telling you that the average number of these plants per m2 is 10.2 with a standard deviation of the mean = 0.5. You have a set of fifty observations in hand obtained by sweaty (underwater) labor in the field. Execute the following steps.

### 1 
Simulate 50 data points form a Poisson with mean 7.5. We are calling this our example data. 
```{r}
set.seed(10)

y <- rpois(50, 7.5)
```

### 2 - 3 
Plot
```{r}
hist(y, freq = FALSE, breaks = 10)

mu.prior <- 10.2
sigma.prior <- 0.5
```

```{r}
discrete_hist <- function(y) {
  
  z <- data.frame(y) %>% count(y) %>% mutate(prop = prop.table(n))
  plot(z$y, z$prop, type = "h", ylab = "Probability", xlab = "y", main = "Improved histogram of data", 
  frame = T, xaxt = "n", lwd = 3, col = "blue")
  x <- seq(min(z$y), max(z$y), 1)
  axis(side = 1, at = x, labels = x)

}

discrete_hist(y)
```


### 4
Set up a vector containing a sequence of values for θ, the mean number of invasive (eelgrass shoots) plants.

This where I get a little iffy in that the upper bound here seems to be set arbitrarily, but lets go with it for now.
```{r}
step <- 0.01
theta <- seq(0, 20, step)
```

### 5 - 6
Write the mathematical expression for a gamma prior on θ
```{r}
prior <- function(theta, mu = mu.prior, sigma = sigma.prior) dgamma(theta, mu^2 / sigma^2, mu / sigma^2)

plot(theta, prior(theta = theta, mu.prior, sigma.prior))
```

### 8 - 9
What is the mathematical expression for the likelihood [y∣θ] assuming that the data are conditionally independent?
```{r}
like <- function(theta, y){
  L = rep(0, length(theta))
  for(i in 1:length(theta)) L[i] = prod(dpois(y, theta[i], log = FALSE))
  return(L)
}
```

```{r}
plot(theta, like(theta, y = y), type = "l", xlim = c(0, 20), main = "Likelihood", xlab = expression(theta), 
  ylab = expression(paste("[y|", theta, "]")))
```

### 10
What is the mathematical expression for the joint distribution [θ,y]?
```{r}
joint <- function(theta) like(theta, y = y) * prior(theta)

plot(theta, joint(theta), type = "l",  main = "Joint", xlim = c(0, 20), xlab = expression(theta),
  ylab = expression(paste("[y|", theta, "] x [", theta, "]")))
```

### 11
What is the mathematical expression for the marginal probability of the data [y]?
```{r}
Py <- sum(like(theta, y = y) * prior(theta) * step)
```

### 12
What is the mathematical expression for the posterior distribution [θ∣y]? 
```{r}
p.theta <- joint(theta) / Py

plot(theta, p.theta, typ = "l", xlim = c(0, 20), main = "Posterior", xlab = expression(theta), 
  ylab = expression(paste("[ ", theta, " | y]")))
```

```{r}
par(mfrow = (c(2, 3)))
plot(theta, prior(theta), type = "l", ylab = expression(paste("[", theta, "]")), xlab = expression(theta),
  main = "Prior", xlim = c(0, 20))

hist(y, freq = FALSE, breaks = 10, main = "Histogram of data")
discrete_hist(y = y)

plot(theta, like(theta, y = y), type = "l", main = "Likelihood", xlim = c(0, 20), xlab = expression(theta),
  ylab = expression(paste("[y|", theta, "])")))
plot(theta, joint(theta), type = "l", main = "Joint", xlim = c(0, 20), xlab = expression(theta),
  ylab = expression(paste("[y | ", theta, "]) x [", theta, "]")))
plot(theta, p.theta, type = "l", xlim = c(0, 20), main = "Posterior", xlab = expression(theta),
  ylab = expression(paste("[ ", theta, " | y]")))
```

### 14
```{r}
(c <- max(p.theta) / max(like(theta, y)))

like.scaled <- c * like(theta, y)

par(mfrow=c(1, 1))
plot(theta, like.scaled, type = "l", col = "red", xlim = c(0, 15), xlab = expression(theta),
  main = "Scaled Overlay", ylab = "Probability density")
lines(theta, p.theta, type = "l")
lines(theta, prior(theta), col = "blue")
legend(0, 1, c("Scaled likelihood","Posterior", "Prior"), lty = rep("solid",3), col = c("red", "black", "blue"))
```

### More realistic eelgrass example

#### Data
```{r}
## Prior data from preliminary sampling ##
mu.prior <- 20
sigma.prior <- 10

## simulated new sampled data (e.g. 1 year post construction) ##
y <- rpois(50, 10)
```

#### Parameters and probabilities
```{r}
## Theta: mean number of shoots ##
step <- 0.1
theta <- seq(0, 40, step)

## Prior distribution ##
prior <- function(theta, mu = mu.prior, sigma = sigma.prior) dgamma(theta, mu^2 / sigma^2, mu / sigma^2)
plot(theta, prior(theta = theta, mu.prior, sigma.prior))

## Liklihood: probability of theta given the data ##
like <- function(theta, y){
  L = rep(0, length(theta))
  for(i in 1:length(theta)) L[i] = prod(dpois(y, theta[i], log = FALSE))
  return(L)
}

plot(theta, like(theta, y = y), type = "l", xlim = c(0, 20), main = "Likelihood", xlab = expression(theta), 
  ylab = expression(paste("[y|", theta, "]")))

## Joint ##
joint <- function(theta) like(theta, y = y) * prior(theta)
plot(theta, joint(theta), type = "l",  main = "Joint", xlim = c(0, 20), xlab = expression(theta),
  ylab = expression(paste("[y|", theta, "] x [", theta, "]")))

## Marginal probability ##
Py <- sum(like(theta, y = y) * prior(theta) * step, na.rm = TRUE)

## Posterior ##
p.theta <- joint(theta) / Py
plot(theta, p.theta, typ = "l", xlim = c(0, 20), main = "Posterior", xlab = expression(theta), 
  ylab = expression(paste("[ ", theta, " | y]")))
```

#### Plots
```{r}
## Grid ##
par(mfrow = (c(2, 3)))

plot(theta, prior(theta), type = "l", ylab = expression(paste("[", theta, "]")), xlab = expression(theta),
  main = "Prior")

hist(y, freq = FALSE, breaks = 10, main = "Histogram of data")

discrete_hist(y = y)

plot(theta, like(theta, y = y), type = "l", main = "Likelihood", xlab = expression(theta), ylab = expression(paste("[y|", theta, "])")))

plot(theta, joint(theta), type = "l", main = "Joint", xlab = expression(theta), ylab = expression(paste("[y | ", theta, "]) x [", theta, "]")))

plot(theta, p.theta, type = "l", main = "Posterior", xlab = expression(theta), ylab = expression(paste("[ ", theta, " | y]")))

## Single overlay ##
(c <- max(p.theta, na.rm = TRUE) / max(like(theta, y), na.rm = TRUE))

like.scaled <- c * like(theta, y)

par(mfrow=c(1, 1))
plot(theta, like.scaled, type = "l", col = "red", xlim = c(0, 40), xlab = expression(theta),
  main = "Scaled Overlay", ylab = "Probability density")
lines(theta, p.theta, type = "l")
lines(theta, prior(theta), col = "blue")
legend(2, 0.6, c("Scaled likelihood","Posterior", "Prior"), lty = rep("solid",3), col = c("red", "black", "blue"))
```

### With rmBayes

#### Simulate data
```{r}
dat <- data.frame(time = c(rep("init", 30), rep("yr1", 30)),
                  shoots = c(rpois(30, 20), rpois(30, 10)))

mu_init <- mean(dat$shoots[dat$time=="init"])
sigma_inti <- sd(dat$shoots[dat$time=="init"])
mu_yr1 <- mean(dat$shoots[dat$time=="yr1"])
sigma_yr1 <- sd(dat$shoots[dat$time=="yr1"])
```

#### Using BayesFactor
```{r}
bf_rmanova <- anovaBF(shoots ~ time, whichRandom = "time", data = dat)
bf_rmanova
```

### Hobbs suggested approach

#### Example of ANOVA from internet
https://web.pdx.edu/~joel8/resources/ConceptualPresentationResources/JAGS_ANOVA.pdf

```{r}
## Data ##
mdat = list('grp'=gl(3,4), 'ngrp'=3, 'N'=12,
'y'=c(2,1,3,2, 2,6,2,2, 6,10,7,5))

## JAGS ##
mt = '
model{
  for(i in 1:N){
    y[i] ~ dnorm(mu[i], err.prec)
  mu[i] = alpha + beta[grp[i]]
  }

  err.prec ~ dgamma(1.0E-3,1.0E-3)
  rse = pow(err.prec,-.5)
  alpha ~ dnorm(0,1.0E-3)
  beta[1] = 0
  for(i in 2:ngrp){
  beta[i] ~ dnorm(0,1.0E-3)
  }
}'

## Run model ##

ti = textConnection(mt)
cm = jags.model(ti, data=mdat, # model specification and data.
n.chains=2, # two random walkers
# initial values, one set per chain
inits=list(
list('alpha'=0,'beta'=c(NA,.5,.5)),
list('alpha'=2,'beta'=c(NA,1,5))),
# burn-in/adaptation steps before we trust
n.adapt = 1000, quiet=TRUE)
close(ti)

update(cm, 5000)

## Posterior checks ##
pos <- coda.samples(cm, variable.names = c("alpha", "beta", "rse"), n.iter = 5000)

xyplot(window(pos,start=5001,stop=10000))

## Report ##
summary(window(pos, start = 5001, stop = 10000))
```

#### Full example
From help with Chat GPT

##### Data
```{r}
set.seed(123)

## Data ##
pre.dat <- rgamma(100, shape = 30, rate = 1)
post.dat <- rgamma(100, shape = 24, rate = 1)

dat.sim <- data.frame(
  density = c(pre.dat, post.dat),
  time = factor(rep(c("pre", "post"), each = 100))
)
```

##### JAGS

```{r}
jags_code <- "
model {
  # Prior for the common shape (alpha) parameter
  alpha ~ dgamma(0.001, 0.001)
  
  # Priors for group means
  mu_pre ~ dgamma(0.001, 0.001)
  mu_diff ~ dgamma(0.001, 0.001)

  # Likelihood
  for (i in 1:N) {
    mean[i] <- mu_pre + mu_diff * (time[1])
    density[i] ~ dgamma(alpha, 1 / mean[i])
  }
  
  # Posterior summaries
  delta <- mu_diff
}
"
```

##### Run
```{r}
## Specify ##
mod <- jags.model(textConnection(jags_code), data = list(N = nrow(dat.sim), density = dat.sim$density, time = as.integer(dat.sim$time)), n.chains = 3)

## Burn ##
update(mod, 1000)
samples <- coda.samples(mod, variable.names = c("alpha", "mu_pre", "mu_diff", "delta"), n.iter = 5000)

## View ##
summary(samples)

hdi(samples)

dat.sim$time <- relevel(dat.sim$time, ref = "pre")
mod.lm <- glm(dat.sim$density ~ dat.sim$time, family = Gamma(link = "log"))

summary(mod.lm)
```

#### RPubs example
https://rpubs.com/dgolicher/jags_one_way_anova

```{r}
d <- read.csv("https://tinyurl.com/aqm-data/mussels.csv")
```

look at data
```{r}
theme_set(theme_bw())
g0 <- ggplot(d,aes(x=Site,y=Lshell))
g_box<-g0+ geom_boxplot()
g_box
```

Confidence intervals
```{r}
g_mean <- g0 + stat_summary(fun.y=mean,geom="point")
g_mean <- g_mean+stat_summary(fun.data=mean_cl_normal,geom="errorbar")
g_mean
```

Frequentist one-way ANOVA
```{r}
d$Site <- as.factor(d$Site) ## Change to a site number for factor levels. This is for brevity in glht output
mod <- lm(data = d, Lshell~Site)

anova(lm(data = d, Lshell~Site))
summary(mod)

plot(glht(mod, linfct = mcp(Site = "Tukey")))
summary(glht(mod, linfct = mcp(Site = "Tukey")))
```

JAGS
```{r}
d.redu <- d %>% 
  filter(Site %in% c("Site_1", "Site_2")) %>% 
  mutate(Site = as.character(Site))

data=list(y=d.redu$Lshell,
          ind=as.numeric(factor(d.redu$Site)),
          N=length(d.redu$Lshell),
          p=length(unique(d.redu$Site)),
          overall_mean=mean(d.redu$Lshell))

pooled_var="
  model {
      #######  Likelihood
      for (i in 1:N) {                    # Loop through observations
        mu[i] <- Beta[ind[i]]               # The expected values are just the group means
        y[i] ~ dnorm(mu[i],tau)           # Values treated as from a single normal
       
      }
     ############## Uninformative priors
    for (j in 1:p) {
     Beta[j] ~ dnorm(0,0.0001)
   
     Effect[j] <- Beta[j] - overall_mean  ### Calculate difference from overall mean
     ################### Calculate pair wise differences 
      for (n in 1:(j-1)){
        Difbeta[n,j] <- Beta[n]-Beta[j]
      }
    }
    
    tau ~ dgamma(scale, rate) ## Prior for normal distribution precision.
    scale ~ dunif(0, 1)       ### Hyper parameters for tau.
    rate ~ dunif(0, 1)
    
  }
"

mod.bys <- jags.model(textConnection(pooled_var),data=data)
```

refine
```{r}
update(mod.bys, n.iter = 1000)
output = coda.samples(model=mod.bys, variable.names = c("Difbeta","Effect"), n.iter=100000, thin=10)

ms <-ggs(output) 
mt <- filter(ms,grepl("Difbeta", Parameter))
ggs_caterpillar(mt) + geom_vline(xintercept = 0,col="red")

mt<-filter(ms,grepl("Effect",Parameter))
ggs_caterpillar(mt) +geom_vline(xintercept = 0,col="red")
```

##### Building off RPubs Example
from above

###### Data
```{r}
set.seed(5)

## Data ##
pre.dat <- c(rpois(65, lambda = 30), rep(0, 35))
post.dat <- c(rpois(60, lambda = 24 ), rep(0, 40))

dat.sim <- data.frame(
  density = c(pre.dat, post.dat),
  time = factor(rep(c("initial", "post"), each = 100))
)

ggplot(dat.sim) +
  geom_histogram(aes(density), binwidth = 1) +
  facet_wrap(~time)
```

###### Model
```{r}
## Define data object ##
d <- list(
  y = as.numeric(dat.sim$density), # Convert 'y' to numeric
  time = as.numeric(factor(dat.sim$time)),
  N = length(dat.sim$density),
  p = length(unique(as.numeric(factor(dat.sim$time)))),
  overall_mean = mean(dat.sim$density),
  lambda = 1
)

## JAGS ##
jags.mod <-  "
model {
  for (i in 1:length(density)) {
    density[i] ~ dpois(lambda[time[i]])
  }

  lambda[1] ~ dgamma(1, 0.01)  # Prior for initial time
  lambda[2] ~ dgamma(1, 0.01)  # Prior for post time

  delta_lambda <- lambda[2] - lambda[1]
  delta_lam_fac <- (lambda[2] - lambda[1]) / lambda[1]

  # Effect size
  effect_size <- delta_lambda / sqrt((lambda[1] + lambda[2]) / 2)

  # Pooled variance estimate
  sigma2 ~ dgamma(0.001, 0.001)

  # Convert variance to standard deviation
  sigma <- sqrt(sigma2)
}
"

## Fit ##
mod.bys <- jags.model(textConnection(jags.mod), data = dat.sim)
```

refine
```{r}
update(mod.bys, n.iter = 1000)
output <- coda.samples(model = mod.bys, 
                      variable.names = c("lambda", "effect_size", "sigma", "delta_lambda", "delta_lam_fac"), 
                      n.iter=10000, 
                      thin=10)

## Lambda ##
ggplot(ms)

ms <- ggs(output) 
mt <- filter(ms, grepl("lambda", Parameter))
ggs_caterpillar(mt) + geom_vline(xintercept = 0,col="red")

mt <- filter(ms, grepl("effect_size", Parameter))
ggs_caterpillar(mt) + geom_vline(xintercept = 0,col="red")

mt <- filter(ms, grepl("delta_lam_fac", Parameter))
ggs_caterpillar(mt) + geom_vline(xintercept = 0,col="red")

summary(output)

summary(glm(density~time, family = poisson(link = "log"), data = dat.sim))
```

###### N calc

```{r}
# Set the seed for reproducibility
set.seed(123)

# Set the target effect size and confidence level
target_effect_size <- -1.6094  # The desired effect size
confidence_level <- 0.90  # 90% confidence level

# Initialize variables
sample_sizes <- 1:500  # Sample sizes to try
simulations <- 1000  # Number of simulations for each sample size
success_probabilities <- numeric(length(sample_sizes))  # Store success probabilities

# Define the JAGS model code (as provided earlier)

# Perform the simulation for different sample sizes
for (i in 1:length(sample_sizes)) {
  success_count <- 0  # Count of successful simulations
  
  for (j in 1:simulations) {
    # Generate data with the current sample size
    N_sim <- sample_sizes[i]
    pre.dat <- c(rpois(N_sim, lambda = 30), rep(0, 100 - N_sim))
    post.dat <- c(rpois(N_sim, lambda = 24), rep(0, 100 - N_sim))
    
    dat.sim <- data.frame(
      density = c(pre.dat, post.dat),
      time = factor(rep(c("initial", "post"), each = 100))
    )
    
    # Create a JAGS model with the current data
    model <- jags.model(textConnection(model_code), data = dat.sim, n.chains = 3)
    
    # Burn-in and sampling
    update(model, 1000)
    samples <- coda.samples(model, variable.names = c("effect_size"), n.iter = 2000)
    
    # Extract the posterior samples of the effect size
    effect_size_samples <- samples[[1]]$effect_size
    
    # Check if the effect size is greater than or equal to the target effect size
    if (any(effect_size_samples >= target_effect_size)) {
      success_count <- success_count + 1
    }
  }
  
  # Calculate the success probability for the current sample size
  success_probabilities[i] <- success_count / simulations
}

# Find the sample size that meets the desired success probability
selected_sample_size <- sample_sizes[min(which(success_probabilities >= confidence_level))]

# Output the selected sample size and success probabilities
cat("Selected Sample Size:", selected_sample_size, "\n")
cat("Success Probabilities:", success_probabilities, "\n")

```

