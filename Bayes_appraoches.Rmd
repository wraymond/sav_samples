---
title: "Bayes_approaches"
author: "Wendel Raymond"
date: "`r Sys.Date()`"
output: html_document
editor_options: 
  chunk_output_type: console
---
```{r}
library(tidyverse)
library(HDInterval)
library(BayesFactor)
library(rjags)
library(kableExtra)
library(ggmcmc)
library(polspline)
library(propagate)
library(multcomp)
library(pwr)
library(parallel)
library(doParallel)
```


## Bayesian appraoches to SAV calculations
Following Hobbs and Hooten texts and code. Bayes Theorem Lab from Bayesian Modeling for Ecologists

You are interested in estimating the posterior distribution for the mean number of individuals of an invasive plant species per m2 in a disturbed grassland (or we can think eelgrass shoots). We will call that mean θ (mean shoot density). You have prior information telling you that the average number of these plants per m2 is 10.2 with a standard deviation of the mean = 0.5. You have a set of fifty observations in hand obtained by sweaty (underwater) labor in the field. Execute the following steps.

### 1 
Simulate 50 data points form a Poisson with mean 7.5. We are calling this our example data. 
```{r}
set.seed(10)

y <- rpois(50, 7.5)
```

### 2 - 3 
Plot
```{r}
hist(y, freq = FALSE, breaks = 10)

mu.prior <- 10.2
sigma.prior <- 0.5
```

```{r}
discrete_hist <- function(y) {
  
  z <- data.frame(y) %>% count(y) %>% mutate(prop = prop.table(n))
  plot(z$y, z$prop, type = "h", ylab = "Probability", xlab = "y", main = "Improved histogram of data", 
  frame = T, xaxt = "n", lwd = 3, col = "blue")
  x <- seq(min(z$y), max(z$y), 1)
  axis(side = 1, at = x, labels = x)

}

discrete_hist(y)
```


### 4
Set up a vector containing a sequence of values for θ, the mean number of invasive (eelgrass shoots) plants.

This where I get a little iffy in that the upper bound here seems to be set arbitrarily, but lets go with it for now.
```{r}
step <- 0.01
theta <- seq(0, 20, step)
```

### 5 - 6
Write the mathematical expression for a gamma prior on θ
```{r}
prior <- function(theta, mu = mu.prior, sigma = sigma.prior) dgamma(theta, mu^2 / sigma^2, mu / sigma^2)

plot(theta, prior(theta = theta, mu.prior, sigma.prior))
```

### 8 - 9
What is the mathematical expression for the likelihood [y∣θ] assuming that the data are conditionally independent?
```{r}
like <- function(theta, y){
  L = rep(0, length(theta))
  for(i in 1:length(theta)) L[i] = prod(dpois(y, theta[i], log = FALSE))
  return(L)
}
```

```{r}
plot(theta, like(theta, y = y), type = "l", xlim = c(0, 20), main = "Likelihood", xlab = expression(theta), 
  ylab = expression(paste("[y|", theta, "]")))
```

### 10
What is the mathematical expression for the joint distribution [θ,y]?
```{r}
joint <- function(theta) like(theta, y = y) * prior(theta)

plot(theta, joint(theta), type = "l",  main = "Joint", xlim = c(0, 20), xlab = expression(theta),
  ylab = expression(paste("[y|", theta, "] x [", theta, "]")))
```

### 11
What is the mathematical expression for the marginal probability of the data [y]?
```{r}
Py <- sum(like(theta, y = y) * prior(theta) * step)
```

### 12
What is the mathematical expression for the posterior distribution [θ∣y]? 
```{r}
p.theta <- joint(theta) / Py

plot(theta, p.theta, typ = "l", xlim = c(0, 20), main = "Posterior", xlab = expression(theta), 
  ylab = expression(paste("[ ", theta, " | y]")))
```

```{r}
par(mfrow = (c(2, 3)))
plot(theta, prior(theta), type = "l", ylab = expression(paste("[", theta, "]")), xlab = expression(theta),
  main = "Prior", xlim = c(0, 20))

hist(y, freq = FALSE, breaks = 10, main = "Histogram of data")
discrete_hist(y = y)

plot(theta, like(theta, y = y), type = "l", main = "Likelihood", xlim = c(0, 20), xlab = expression(theta),
  ylab = expression(paste("[y|", theta, "])")))
plot(theta, joint(theta), type = "l", main = "Joint", xlim = c(0, 20), xlab = expression(theta),
  ylab = expression(paste("[y | ", theta, "]) x [", theta, "]")))
plot(theta, p.theta, type = "l", xlim = c(0, 20), main = "Posterior", xlab = expression(theta),
  ylab = expression(paste("[ ", theta, " | y]")))
```

### 14
```{r}
(c <- max(p.theta) / max(like(theta, y)))

like.scaled <- c * like(theta, y)

par(mfrow=c(1, 1))
plot(theta, like.scaled, type = "l", col = "red", xlim = c(0, 15), xlab = expression(theta),
  main = "Scaled Overlay", ylab = "Probability density")
lines(theta, p.theta, type = "l")
lines(theta, prior(theta), col = "blue")
legend(0, 1, c("Scaled likelihood","Posterior", "Prior"), lty = rep("solid",3), col = c("red", "black", "blue"))
```

### More realistic eelgrass example

#### Data
```{r}
## Prior data from preliminary sampling ##
mu.prior <- 20
sigma.prior <- 10

## simulated new sampled data (e.g. 1 year post construction) ##
y <- rpois(50, 10)
```

#### Parameters and probabilities
```{r}
## Theta: mean number of shoots ##
step <- 0.1
theta <- seq(0, 40, step)

## Prior distribution ##
prior <- function(theta, mu = mu.prior, sigma = sigma.prior) dgamma(theta, mu^2 / sigma^2, mu / sigma^2)
plot(theta, prior(theta = theta, mu.prior, sigma.prior))

## Liklihood: probability of theta given the data ##
like <- function(theta, y){
  L = rep(0, length(theta))
  for(i in 1:length(theta)) L[i] = prod(dpois(y, theta[i], log = FALSE))
  return(L)
}

plot(theta, like(theta, y = y), type = "l", xlim = c(0, 20), main = "Likelihood", xlab = expression(theta), 
  ylab = expression(paste("[y|", theta, "]")))

## Joint ##
joint <- function(theta) like(theta, y = y) * prior(theta)
plot(theta, joint(theta), type = "l",  main = "Joint", xlim = c(0, 20), xlab = expression(theta),
  ylab = expression(paste("[y|", theta, "] x [", theta, "]")))

## Marginal probability ##
Py <- sum(like(theta, y = y) * prior(theta) * step, na.rm = TRUE)

## Posterior ##
p.theta <- joint(theta) / Py
plot(theta, p.theta, typ = "l", xlim = c(0, 20), main = "Posterior", xlab = expression(theta), 
  ylab = expression(paste("[ ", theta, " | y]")))
```

#### Plots
```{r}
## Grid ##
par(mfrow = (c(2, 3)))

plot(theta, prior(theta), type = "l", ylab = expression(paste("[", theta, "]")), xlab = expression(theta),
  main = "Prior")

hist(y, freq = FALSE, breaks = 10, main = "Histogram of data")

discrete_hist(y = y)

plot(theta, like(theta, y = y), type = "l", main = "Likelihood", xlab = expression(theta), ylab = expression(paste("[y|", theta, "])")))

plot(theta, joint(theta), type = "l", main = "Joint", xlab = expression(theta), ylab = expression(paste("[y | ", theta, "]) x [", theta, "]")))

plot(theta, p.theta, type = "l", main = "Posterior", xlab = expression(theta), ylab = expression(paste("[ ", theta, " | y]")))

## Single overlay ##
(c <- max(p.theta, na.rm = TRUE) / max(like(theta, y), na.rm = TRUE))

like.scaled <- c * like(theta, y)

par(mfrow=c(1, 1))
plot(theta, like.scaled, type = "l", col = "red", xlim = c(0, 40), xlab = expression(theta),
  main = "Scaled Overlay", ylab = "Probability density")
lines(theta, p.theta, type = "l")
lines(theta, prior(theta), col = "blue")
legend(2, 0.6, c("Scaled likelihood","Posterior", "Prior"), lty = rep("solid",3), col = c("red", "black", "blue"))
```

### With rmBayes

#### Simulate data
```{r}
dat <- data.frame(time = c(rep("init", 30), rep("yr1", 30)),
                  shoots = c(rpois(30, 20), rpois(30, 10)))

mu_init <- mean(dat$shoots[dat$time=="init"])
sigma_inti <- sd(dat$shoots[dat$time=="init"])
mu_yr1 <- mean(dat$shoots[dat$time=="yr1"])
sigma_yr1 <- sd(dat$shoots[dat$time=="yr1"])
```

#### Using BayesFactor
```{r}
bf_rmanova <- anovaBF(shoots ~ time, whichRandom = "time", data = dat)
bf_rmanova
```

### Hobbs suggested approach

#### Example of ANOVA from internet
https://web.pdx.edu/~joel8/resources/ConceptualPresentationResources/JAGS_ANOVA.pdf

```{r}
## Data ##
mdat = list('grp'=gl(3,4), 'ngrp'=3, 'N'=12,
'y'=c(2,1,3,2, 2,6,2,2, 6,10,7,5))

## JAGS ##
mt = '
model{
  for(i in 1:N){
    y[i] ~ dnorm(mu[i], err.prec)
  mu[i] = alpha + beta[grp[i]]
  }

  err.prec ~ dgamma(1.0E-3,1.0E-3)
  rse = pow(err.prec,-.5)
  alpha ~ dnorm(0,1.0E-3)
  beta[1] = 0
  for(i in 2:ngrp){
  beta[i] ~ dnorm(0,1.0E-3)
  }
}'

## Run model ##

ti = textConnection(mt)
cm = jags.model(ti, data=mdat, # model specification and data.
n.chains=2, # two random walkers
# initial values, one set per chain
inits=list(
list('alpha'=0,'beta'=c(NA,.5,.5)),
list('alpha'=2,'beta'=c(NA,1,5))),
# burn-in/adaptation steps before we trust
n.adapt = 1000, quiet=TRUE)
close(ti)

update(cm, 5000)

## Posterior checks ##
pos <- coda.samples(cm, variable.names = c("alpha", "beta", "rse"), n.iter = 5000)

xyplot(window(pos,start=5001,stop=10000))

## Report ##
summary(window(pos, start = 5001, stop = 10000))
```

#### Full example
From help with Chat GPT

##### Data
```{r}
set.seed(123)

## Data ##
pre.dat <- rgamma(100, shape = 30, rate = 1)
post.dat <- rgamma(100, shape = 24, rate = 1)

dat.sim <- data.frame(
  density = c(pre.dat, post.dat),
  time = factor(rep(c("pre", "post"), each = 100))
)
```

##### JAGS

```{r}
jags_code <- "
model {
  # Prior for the common shape (alpha) parameter
  alpha ~ dgamma(0.001, 0.001)
  
  # Priors for group means
  mu_pre ~ dgamma(0.001, 0.001)
  mu_diff ~ dgamma(0.001, 0.001)

  # Likelihood
  for (i in 1:N) {
    mean[i] <- mu_pre + mu_diff * (time[1])
    density[i] ~ dgamma(alpha, 1 / mean[i])
  }
  
  # Posterior summaries
  delta <- mu_diff
}
"
```

##### Run
```{r}
## Specify ##
mod <- jags.model(textConnection(jags_code), data = list(N = nrow(dat.sim), density = dat.sim$density, time = as.integer(dat.sim$time)), n.chains = 3)

## Burn ##
update(mod, 1000)
samples <- coda.samples(mod, variable.names = c("alpha", "mu_pre", "mu_diff", "delta"), n.iter = 5000)

## View ##
summary(samples)

hdi(samples)

dat.sim$time <- relevel(dat.sim$time, ref = "pre")
mod.lm <- glm(dat.sim$density ~ dat.sim$time, family = Gamma(link = "log"))

summary(mod.lm)
```

#### RPubs example
https://rpubs.com/dgolicher/jags_one_way_anova

```{r}
d <- read.csv("https://tinyurl.com/aqm-data/mussels.csv")
```

look at data
```{r}
theme_set(theme_bw())
g0 <- ggplot(d,aes(x=Site,y=Lshell))
g_box<-g0+ geom_boxplot()
g_box
```

Confidence intervals
```{r}
g_mean <- g0 + stat_summary(fun.y=mean,geom="point")
g_mean <- g_mean+stat_summary(fun.data=mean_cl_normal,geom="errorbar")
g_mean
```

Frequentist one-way ANOVA
```{r}
d$Site <- as.factor(d$Site) ## Change to a site number for factor levels. This is for brevity in glht output
mod <- lm(data = d, Lshell~Site)

anova(lm(data = d, Lshell~Site))
summary(mod)

plot(glht(mod, linfct = mcp(Site = "Tukey")))
summary(glht(mod, linfct = mcp(Site = "Tukey")))
```

JAGS
```{r}
d.redu <- d %>% 
  filter(Site %in% c("Site_1", "Site_2")) %>% 
  mutate(Site = as.character(Site))

data=list(y=d.redu$Lshell,
          ind=as.numeric(factor(d.redu$Site)),
          N=length(d.redu$Lshell),
          p=length(unique(d.redu$Site)),
          overall_mean=mean(d.redu$Lshell))

pooled_var="
  model {
      #######  Likelihood
      for (i in 1:N) {                    # Loop through observations
        mu[i] <- Beta[ind[i]]               # The expected values are just the group means
        y[i] ~ dnorm(mu[i],tau)           # Values treated as from a single normal
       
      }
     ############## Uninformative priors
    for (j in 1:p) {
     Beta[j] ~ dnorm(0,0.0001)
   
     Effect[j] <- Beta[j] - overall_mean  ### Calculate difference from overall mean
     ################### Calculate pair wise differences 
      for (n in 1:(j-1)){
        Difbeta[n,j] <- Beta[n]-Beta[j]
      }
    }
    
    tau ~ dgamma(scale, rate) ## Prior for normal distribution precision.
    scale ~ dunif(0, 1)       ### Hyper parameters for tau.
    rate ~ dunif(0, 1)
    
  }
"

mod.bys <- jags.model(textConnection(pooled_var),data=data)
```

refine
```{r}
update(mod.bys, n.iter = 1000)
output = coda.samples(model=mod.bys, variable.names = c("Difbeta","Effect"), n.iter=100000, thin=10)

ms <-ggs(output) 
mt <- filter(ms,grepl("Difbeta", Parameter))
ggs_caterpillar(mt) + geom_vline(xintercept = 0,col="red")

mt<-filter(ms,grepl("Effect",Parameter))
ggs_caterpillar(mt) +geom_vline(xintercept = 0,col="red")
```

##### Building off RPubs Example
from above

###### Data
```{r}
set.seed(123)

# Define sample sizes for pre and post-treatment groups
N <- 100  # Assuming 100 observations in each group

# Real world values
mean_pre <- 30
mean_post <- 24

sd_pre <- 10
sd_post <- 8

# Parameters for the gamma distribution
alpha_pre <- (mean_pre^2) / (sd_pre^2)  # Shape parameter for pre-treatment group
beta_pre <- (sd_pre^2) / mean_pre  # Rate parameter for pre-treatment group

alpha_post <- (mean_post^2) / (sd_post ^2)  # Shape parameter for post-treatment group
beta_post <- (sd_post ^2) / mean_post  # Rate parameter for post-treatment group

# Generate gamma-distributed data for pre and post-treatment groups
pre.dat <- rgamma(N, shape = alpha_pre, rate = beta_pre)
post.dat <- rgamma(N, shape = alpha_post, rate = beta_post)

# Create a data frame
dat.sim <- data.frame(
  density = c(pre.dat, post.dat),
  time = factor(rep(c("pre", "post"), each = N))
)

# Summary statistics
summary(pre.dat)
summary(post.dat)

ggplot(dat.sim) +
  geom_histogram(aes(density), binwidth = 1) +
  facet_wrap(~time)
```

###### Model
```{r}
## JAGS ##
jags.mod <- "
model {
  for (i in 1:2) {
    for (j in 1:N) {
      y[i, j] ~ dgamma(alpha[time[i]], beta[time[[i]])
    }
  }

  for (i in 1:2) {
    mu[i] ~ dnorm(mu0, tau)
  }

  mu0 ~ dnorm(0, 1.0E-6)
  tau ~ dgamma(1.0E-3, 1.0E-3)
  alpha[1] ~ dgamma(1.0E-3, 1.0E-3)
  beta[1] ~ dgamma(1.0E-3, 1.0E-3)
  alpha[2] ~ dgamma(1.0E-3, 1.0E-3)
  beta[2] ~ dgamma(1.0E-3, 1.0E-3)
  beta_post ~ dgamma(1.0E-3, 1.0E-3)
}
"

## Fit ##
mod.bys <- jags.model(textConnection(jags.mod), data =  list(y = as.matrix(dat.sim$density), N = N))
```

refine
```{r}
update(mod.bys, n.iter = 1000)
output <- coda.samples(model = mod.bys, 
                      variable.names = c("lambda", "effect_size", "sigma", "delta_lambda", "delta_lam_fac"), 
                      n.iter=10000, 
                      thin=10)

ms <- ggs(output) 
mt <- filter(ms, grepl("lambda", Parameter))
ggs_caterpillar(mt) + geom_vline(xintercept = 0,col="red")

mt <- filter(ms, grepl("effect_size", Parameter))
ggs_caterpillar(mt) + geom_vline(xintercept = 0,col="red")

mt <- filter(ms, grepl("delta_lam_fac", Parameter))
ggs_caterpillar(mt) + geom_vline(xintercept = 0,col="red")

summary(output)

summary(glm(density~time, family = Gamma(link = "log"), data = dat.sim))
```

###### N calc

```{r}
# Set parameters
effect_size <- -0.2  # Desired difference in lambda
alpha <- 0.1  # Significance level
beta <- 0.1  # Desired Type II error (1 - power)
lambda_baseline <- 19  # Initial Poisson rate (for example)
sample_sizes <- 1:100  # Range of sample sizes to try
simulations_per_sample_size <- 100  # Number of simulations for each sample size

# Initialize variables to store results
sample_size_results <- numeric(length(sample_sizes))

# Perform power analysis for each sample size
for (i in 1:length(sample_sizes)) {
  sample_size <- sample_sizes[i]
  significant_results <- 0  # Count of successful simulations for this sample size
  
  for (j in 1:simulations_per_sample_size) {
    # Generate data for baseline and changed rates
    pre.dat <- rpois(sample_size, lambda = lambda_baseline)
    post.dat <- rpois(sample_size, lambda = lambda_baseline + (lambda_baseline * effect_size))
    
    # Create a data frame for Poisson regression
    data <- data.frame(
      y = c(pre.dat, post.dat),
      group = factor(rep(1:2, each = sample_size))
    )
    
    # Perform Poisson regression
    model <- glm(y ~ group, data = data, family = poisson)
    
    # Check if the coefficient for 'group2' (representing the change) is significant
    p_value <- summary(model)$coefficients["group2", "Pr(>|z|)"]
    
    # Check if the test is significant at the desired alpha level
    if (p_value < alpha) {
      significant_results <- significant_results + 1
    }
  }
  
  # Calculate the probability of detecting a difference for this sample size
  probability <- significant_results / simulations_per_sample_size
  sample_size_results[i] <- probability
}

# Output the sample sizes and corresponding probabilities
result_df <- data.frame(Sample_Size = sample_sizes, Probability = sample_size_results)

ggplot(result_df) + 
  geom_point(aes(x = Sample_Size, y = Probability)) + 
  geom_hline(aes(yintercept = 0.9), color = "red")

```

